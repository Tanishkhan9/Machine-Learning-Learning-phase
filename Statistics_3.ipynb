{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive Statistic :\n",
        "\n",
        "Statistics is the foundation of data science. Descriptive statistics are simple tools that help us understand and summarize data. They show the basic features of a dataset, like the average, highest and lowest values and how spread out the numbers are. It's the first step in making sense of information.\n",
        "\n",
        "# Types of Descriptive Statistics\n",
        "\n",
        "There are three categories for standard classification of descriptive statistics methods, each serving different purposes in summarizing and describing data. They help us understand:\n",
        "\n",
        "Where the data centers (Measures of Central Tendency)\n",
        "\n",
        "How spread out the data is (Measure of Variability)\n",
        "\n",
        "How the data is distributed (Measures of Frequency Distribution)\n",
        "\n",
        "# 1. Measures of Central Tendency\n",
        "\n",
        "Statistical values that describe the central position within a dataset. There are three main measures of central tendency:\n",
        "\n",
        "Mean , Mode , Median"
      ],
      "metadata": {
        "id": "p7cnNfvDuprK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean:\n",
        "is the sum of observations divided by the total number of observations. It is also defined as average which is the sum divided by count.\n",
        "\n",
        "Mean= ∑x/n\n",
        "​\n",
        "\n",
        " where,\n",
        "\n",
        "x = Observations\n",
        "\n",
        "n = number of terms\n"
      ],
      "metadata": {
        "id": "OfXQefoA2Xgk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcPO85JUuWNz",
        "outputId": "62da9243-62b1-4ebe-eb97-9aa8cda79992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean =  7.333333333333333\n"
          ]
        }
      ],
      "source": [
        "#Let's look at an example of how can we find the mean of a data set using python code implementation.\n",
        "# Before its implementation we should have some basic knowledge about numpy and scipy.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Sample Data\n",
        "arr = [5, 6, 11]\n",
        "\n",
        "# Mean\n",
        "mean = np.mean(arr)\n",
        "\n",
        "print(\"Mean = \", mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mode:\n",
        " The most frequently occurring value in the dataset. It’s useful for categorical data and in cases where knowing the most common choice is crucial."
      ],
      "metadata": {
        "id": "x5I_JFfh2wre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# sample Data\n",
        "arr = [1, 2, 2, 3]\n",
        "\n",
        "# Mode\n",
        "mode = stats.mode(arr)\n",
        "print(\"Mode = \", mode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a_GFK4J28WP",
        "outputId": "b114337f-b497-49a0-bdbc-37cd29d2a397"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode =  ModeResult(mode=np.int64(2), count=np.int64(2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Median:\n",
        "The median is the middle value in a sorted dataset. If the number of values is odd, it's the center value, if even, it's the average of the two middle values. It's often better than the mean for skewed data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n1_a2mgI2_D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# sample Data\n",
        "arr = [1, 2, 3, 4]\n",
        "\n",
        "# Median\n",
        "median = np.median(arr)\n",
        "\n",
        "print(\"Median = \", median)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuTe1s2S3A78",
        "outputId": "23fdbef7-28f5-45ea-9d8e-f31cd4d97b6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median =  2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : All implementations are performed using numpy library in python. If you want to learn and understand more about it.\n",
        "\n",
        "Central tendency measures are the foundation for understanding data distribution and identifying anomalies. For example, the mean can reveal trends, while the median highlights skewed distributions."
      ],
      "metadata": {
        "id": "MxBmqgKq3EZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Measure of Variability\n",
        "Knowing not just where the data centers but also how it spreads out is important. Measures of variability, also called measures of dispersion, help us spot the spread or distribution of observations in a dataset. They identifying outliers, assessing model assumptions and understanding data variability in relation to its mean.\n",
        " The key measures of variability include:\n",
        "\n",
        "**1. Range :**\n",
        " describes the difference between the largest and smallest data point in our data set. The bigger the range, the more the spread of data and vice versa. While easy to compute range is sensitive to outliers. This measure can provide a quick sense of the data spread but should be complemented with other statistics.\n",
        "\n",
        "**Range = Largest data value - smallest data value **"
      ],
      "metadata": {
        "id": "Jl57ALmu3JG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample Data\n",
        "arr = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Finding Max\n",
        "Maximum = max(arr)\n",
        "# Finding Min\n",
        "Minimum = min(arr)\n",
        "\n",
        "# Difference Of Max and Min\n",
        "Range = Maximum-Minimum\n",
        "print(\"Maximum = {}, Minimum = {} and Range = {}\".format(\n",
        "    Maximum, Minimum, Range))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwCT6eLF3Una",
        "outputId": "1b2beec8-a022-4b2d-b6c0-9c82f84cb4b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum = 5, Minimum = 1 and Range = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.** Variance: **\n",
        "is defined as an average squared deviation from the mean. It is calculated by finding the difference between every data point and the average which is also known as the mean, squaring them, adding all of them and then dividing by the number of data points present in our data set.\n",
        "\n",
        "σ^2 =∑(x−μ)^2/N\n",
        "\n",
        "\n",
        "where,\n",
        "\n",
        "x -> Observation under consideration\n",
        "\n",
        "N -> number of terms\n",
        "\n",
        "mu -> Mean"
      ],
      "metadata": {
        "id": "Quq6mLfU3X1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "# sample data\n",
        "arr = [1, 2, 3, 4, 5]\n",
        "# variance\n",
        "print(\"Var = \", (statistics.variance(arr)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ_EPqJv3lFc",
        "outputId": "37ccb8a1-1ce7-470a-ac21-61989c3eee55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Var =  2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Standard deviation:**\n",
        " Standard deviation is widely used to measure the extent of variation or dispersion in data. It's especially important when assessing model performance (e.g., residuals) or comparing datasets with different means.\n",
        "\n",
        "It is defined as the square root of the variance. It is calculated by finding the mean, then subtracting each number from the mean which is also known as the average and squaring the result. Adding all the values and then dividing by the no of terms followed by the square root.\n",
        "\n",
        "σ= (∑(x−μ)^2/N)^1/2\n",
        "\n",
        " where,\n",
        "\n",
        "x = Observation under consideration\n",
        "\n",
        "N = number of terms\n",
        "\n",
        "mu = Mean"
      ],
      "metadata": {
        "id": "U3tKVvbU3kar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "arr = [1, 2, 3, 4, 5]\n",
        "print(\"Std = \", (statistics.stdev(arr)))"
      ],
      "metadata": {
        "id": "8t4Z7tVB3_GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variability measures are important in residual analysis to check how well a model fits the data.\n",
        "\n",
        "**3. Measures of Frequency Distribution**\n",
        "\n",
        "Frequency distribution table is a powerful summarize way to show how data points are distributed across different categories or intervals. Helps identify patterns, outliers and the overall structure of the dataset. It is often the first step in understand the dataset before applying more advanced analytical methods or creating visualizations like histograms or pie charts.\n",
        "\n",
        "Frequency Distribution Table Includes measure like:\n",
        "\n",
        "Data intervals or categories\n",
        "\n",
        "Frequency counts\n",
        "\n",
        "Relative frequencies (percentages)\n",
        "\n",
        "Cumulative frequencies when needed\n",
        "\n",
        "For Frequency Distribution – Histogram, Bar Graph, Frequency Polygon and Pie\n",
        "\n",
        "Chart read article: Frequency Distribution – Table, Graphs, Formula"
      ],
      "metadata": {
        "id": "zMlv6Lpn4BiM"
      }
    }
  ]
}