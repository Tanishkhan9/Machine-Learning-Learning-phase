{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5OisCGk/OkFameLzAVyES"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mquiaowkpc3l","executionInfo":{"status":"ok","timestamp":1755107676214,"user_tz":-330,"elapsed":43,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"b6b8e1e5-ab4f-48c9-cf5e-81cbcbcc7272"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Score:  0.75\n","Precision Score:  0.75\n","Recall Score:  0.75\n","F1 Score:  0.75\n"]}],"source":["# Import evaluation metrics from scikit-learn\n","from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n","\n","# True labels (Actual values)\n","# Represents the ground truth\n","X = [1, 0, 1, 0, 1, 0, 1, 0]\n","\n","# Predicted labels (Model's predictions)\n","# These are the predictions made by a model\n","y = [1, 1, 1, 0, 0, 0, 1, 0]\n","\n","# Accuracy: (Correct predictions) / (Total predictions)\n","print(\"Accuracy Score: \", accuracy_score(X, y))\n","\n","# Precision: Of all positive predictions, how many were actually correct?\n","# Formula: True Positives / (True Positives + False Positives)\n","print(\"Precision Score: \", precision_score(X, y))\n","\n","# Recall: Of all actual positive values, how many did the model find?\n","# Formula: True Positives / (True Positives + False Negatives)\n","print(\"Recall Score: \", recall_score(X, y))\n","\n","# F1 Score: A weighted average of Precision and Recall\n","# Useful for balancing both metrics, especially with imbalanced data\n","print(\"F1 Score: \", f1_score(X, y))\n"]},{"cell_type":"code","source":["# Import the function to create a confusion matrix from scikit-learn\n","from sklearn.metrics import confusion_matrix\n","\n","# Define the true labels (ground truth)\n","# In this list: 1 = Positive class, 0 = Negative class\n","X = [1, 1, 1, 0, 0, 0, 1, 0] # Actual values\n","\n","# Define the predicted labels from a model\n","y = [1, 1, 0, 1, 0, 0, 0, 1] # Predicted values\n","\n","# Calculate the confusion matrix by comparing true labels (X) with predicted labels (y)\n","cm = confusion_matrix(X, y)\n","\n","# Display the confusion matrix\n","# The output will be a 2x2 NumPy array\n","cm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzg30eBakc5n","executionInfo":{"status":"ok","timestamp":1755107998118,"user_tz":-330,"elapsed":7,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"f84aca7d-3eda-49d6-fdd4-3565657bda6a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2, 2],\n","       [2, 2]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Import specific regression metrics from scikit-learn\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","# Import the NumPy library for numerical operations, especially for the square root\n","import numpy as np\n","\n","# Define the true (actual) target values\n","X = [60, 70, 80, 90, 100]\n","\n","# Define the values predicted by a regression model\n","y = [55, 60, 75, 80, 95]\n","\n","# --- Mean Absolute Error (MAE) ---\n","# Calculates the average of the absolute differences between actual and predicted values.\n","# It's easy to understand because it's in the same units as the original data.\n","mae = mean_absolute_error(X, y)\n","print(\"Mean Absolute Error (MAE):\", mae)\n","\n","# --- Mean Squared Error (MSE) ---\n","# Calculates the average of the squared differences between actual and predicted values.\n","# This metric penalizes larger errors more than smaller ones.\n","mse = mean_squared_error(X, y)\n","print(\"Mean Squared Error (MSE):\", mse)\n","\n","# --- Root Mean Squared Error (RMSE) ---\n","# Calculates the square root of the MSE.\n","# This brings the error metric back to the same units as the target variable, making it more interpretable.\n","rmse = np.sqrt(mse)\n","print(\"Root Mean Squared Error (RMSE):\", rmse)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FpYuFa1Tlrfn","executionInfo":{"status":"ok","timestamp":1755108141303,"user_tz":-330,"elapsed":15,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"748193f8-d91d-4d13-891b-a838b15c084b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7.0\n","55.0\n","7.416198487095663\n"]}]}]}