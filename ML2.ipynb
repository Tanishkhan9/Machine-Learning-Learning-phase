{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXlJQRBfzN/3qyFCHuUDhq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Overall Content Overview: Introduction to Supervised Learning with Linear and Logistic Regression**\n","\n","The two code snippets provided serve as excellent, concise introductions to two of the most fundamental and widely used algorithms in **supervised machine learning**: **Linear Regression** and **Logistic Regression**. Both are used for **predictive modeling**, meaning they learn from past data to make predictions on new, unseen data.\n","\n","### **Core Concept: Supervised Learning**\n","\n","Both Linear and Logistic Regression fall under the umbrella of **Supervised Learning**.\n","*   **Definition:** In supervised learning, the algorithm learns from a \"labeled\" dataset, meaning it has both the input features (`X`) and the corresponding correct output labels (`y`).\n","*   **Goal:** The model learns a mapping from `X` to `y`, so that when new `X` data is presented, it can predict the `y` with reasonable accuracy.\n","*   **Process:**\n","    1.  **Training:** The model is fed historical `X` and `y` data (`model.fit(X, y)`). It \"learns\" the patterns and relationships.\n","    2.  **Prediction:** Once trained, the model can take new `X` values and generate predictions for `y` (`model.predict(new_X)`).\n","\n","### **1. Linear Regression (Regression Task)**\n","\n","*   **Code Example Focus:** `from sklearn.linear_model import LinearRegression`\n","*   **Purpose:** Linear Regression is used for **regression tasks**, which means predicting a **continuous numerical value**.\n","*   **How it Works:**\n","    *   It finds the \"best-fit\" straight line (or hyperplane in higher dimensions) that describes the linear relationship between the input features (`X`) and the target variable (`y`).\n","    *   This line minimizes the sum of the squared differences between the actual `y` values and the `y` values predicted by the line (known as Ordinary Least Squares).\n","    *   The equation for a simple linear regression is typically: `y = mx + b` (where `m` is the slope/coefficient and `b` is the y-intercept).\n","*   **Output:** A single, continuous numerical value (e.g., marks, price, temperature).\n","*   **Typical Use Cases:**\n","    *   Predicting house prices based on size.\n","    *   Forecasting sales based on advertising spend.\n","    *   Estimating a student's marks based on study hours (as in your example).\n","    *   Predicting temperature based on humidity.\n","\n","### **2. Logistic Regression (Classification Task)**\n","\n","*   **Code Example Focus:** `from sklearn.linear_model import LogisticRegression`\n","*   **Purpose:** Logistic Regression is used for **classification tasks**, which means predicting a **categorical outcome** (e.g., Yes/No, True/False, Pass/Fail, Spam/Not Spam). Despite its name, it is *not* a regression algorithm in the sense of predicting continuous values.\n","*   **How it Works:**\n","    *   It uses a \"sigmoid\" (or logistic) function to map the linear combination of input features to a probability value between 0 and 1.\n","    *   This probability is then thresholded (commonly at 0.5) to assign a class label (e.g., if probability > 0.5, classify as 1; otherwise, classify as 0).\n","    *   It learns a decision boundary that separates the different classes in the feature space.\n","*   **Output:**\n","    *   Probabilities of belonging to each class.\n","    *   Direct class labels (e.g., 0 or 1, Pass or Fail).\n","*   **Typical Use Cases:**\n","    *   Spam detection (spam or not spam).\n","    *   Disease diagnosis (positive or negative).\n","    *   Customer churn prediction (will churn or not).\n","    *   Predicting if a student will pass or fail based on study hours (as in your example).\n","\n","### **Key Differences & Similarities:**\n","\n","| Feature               | Linear Regression                                | Logistic Regression                             |\n","| :-------------------- | :----------------------------------------------- | :---------------------------------------------- |\n","| **Purpose**           | **Regression** (predicts continuous values)      | **Classification** (predicts categorical labels) |\n","| **Output Type**       | Continuous numerical value                       | Probability (0-1), then discrete class label    |\n","| **Underlying Function** | Linear equation (`y = mx + b`)                 | Sigmoid function applied to a linear equation   |\n","| **Error Metric**      | Mean Squared Error (MSE) often used              | Cross-entropy or Log-loss often used            |\n","| **Problem Type**      | Predicting \"how much?\" or \"how many?\"            | Predicting \"which category?\" or \"yes/no?\"       |\n","\n","**Similarities:**\n","*   Both are **linear models** (they model a linear relationship between features and an internal score before transformation).\n","*   Both are **supervised learning** algorithms.\n","*   Both are relatively **simple to understand and interpret**.\n","*   Both are available within the `sklearn.linear_model` module and share the consistent `fit()` and `predict()` API.\n","\n","### **Role of `scikit-learn` (`sklearn`)**\n","\n","The `sklearn` library is central to both examples. It provides:\n","*   **Pre-built Algorithms:** Ready-to-use implementations of machine learning models (like `LinearRegression` and `LogisticRegression`).\n","*   **Consistent API:** A uniform way to train (`.fit()`) and predict (`.predict()`) across different models, making it easy to experiment and swap algorithms.\n","*   **Abstraction:** It abstracts away the complex mathematical computations, allowing users to focus on data preparation, model selection, and interpretation.\n","\n","---\n","\n","In summary, these two code snippets provide practical demonstrations of how to apply basic yet powerful machine learning models for different types of predictive tasks (regression and classification) using a standard Python library like `scikit-learn`."],"metadata":{"id":"NIDKjJXyToOJ"}},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHaGSFaKqoSn","executionInfo":{"status":"ok","timestamp":1755018824559,"user_tz":-330,"elapsed":2060,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"b428e95a-79aa-4938-8ec3-fcbf690cda88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the number of hours:5\n","Based on your study hours your predicted marks are 100.00\n"]}],"source":["# Import the LinearRegression class from the sklearn.linear_model module.\n","# This class is used to perform ordinary least squares Linear Regression.\n","from sklearn.linear_model import LinearRegression\n","\n","# Define the feature set (X). In this case, X represents the \"number of hours studied\".\n","# X is a list of lists, where each inner list contains one feature (hours).\n","# This format is required by scikit-learn for single-feature input.\n","X = [[1], [2], [3], [4], [5]]\n","\n","# Define the target variable (y). In this case, y represents the \"marks obtained\".\n","# This is the variable we want to predict.\n","y = [60, 70, 80, 90, 100]\n","\n","# Create an instance of the LinearRegression model.\n","# This initializes the model with default parameters.\n","model = LinearRegression()\n","\n","# Train the linear regression model using the provided data (X and y).\n","# The .fit() method calculates the optimal coefficients (slope) and intercept\n","# that best describe the linear relationship between X and y.\n","model.fit(X, y)\n","\n","# Prompt the user to enter the number of hours they studied.\n","# The input is converted to a float to handle potential decimal values.\n","hours = float(input(\"Enter the number of hours:\"))\n","\n","# Use the trained model to predict the marks based on the user's input hours.\n","# The input for prediction also needs to be in a list of lists format ([[value]]).\n","predicted_marks = model.predict([[hours]])\n","\n","# Print the predicted marks to the console.\n","# The f-string formatting allows embedding variables directly into the string.\n","# predicted_marks is a NumPy array, so [0] is used to access the single predicted value.\n","print(f\"Based on your study hours your predicted marks are {predicted_marks[0]:.2f}\")\n","\n"]},{"cell_type":"code","source":["# Import the LogisticRegression class from the sklearn.linear_model module.\n","# Logistic Regression is a classification algorithm, not a regression algorithm,\n","# despite its name. It's used for predicting categorical outcomes (e.g., Yes/No, Pass/Fail).\n","from sklearn.linear_model import LogisticRegression\n","\n","# Define the feature set (X). In this case, X represents \"number of hours studied\".\n","# It's a list of lists, as scikit-learn expects a 2D array-like input for features.\n","X = [[1], [2], [3], [4], [5], [6]]\n","\n","# Define the target variable (y). In this case, y represents the \"outcome\" (Pass/Fail).\n","# 0 typically denotes one class (e.g., Fail), and 1 denotes another (e.g., Pass).\n","# This is a binary classification problem.\n","y = [0, 0, 0, 1, 1, 1] # 0 = Fail, 1 = Pass\n","\n","# Create an instance of the LogisticRegression model.\n","# This initializes the model, ready to be trained.\n","model = LogisticRegression()\n","\n","# Train the logistic regression model using the provided data (X and y).\n","# The .fit() method finds the best decision boundary (a curve, which is a straight line\n","# in 2D for this simple case) that separates the two classes (0s and 1s).\n","model.fit(X, y)\n","\n","# Prompt the user to enter the number of hours they studied.\n","# The input is converted to a float to allow for non-integer hours.\n","hours = float(input(\"Enter the number of hours you studies:\"))\n","\n","# Use the trained model to predict the outcome (Pass/Fail) based on the user's input hours.\n","# model.predict([[hours]]) will return a NumPy array (e.g., [0] or [1]).\n","# [0] is appended to directly access the single predicted class (0 or 1).\n","Result = model.predict([[hours]])[0]\n","\n","# Use an if-else statement to interpret the prediction and provide a user-friendly message.\n","# If Result is 1, it means the model predicts \"Pass\".\n","if Result == 1:\n","    # Print a message indicating a likely pass based on the hours studied.\n","    print(f\"According to your study hours i.e {hours}, you may Pass\")\n","# If Result is 0, it means the model predicts \"Fail\".\n","else:\n","    # Print a message indicating a likely fail based on the hours studied.\n","    print(f\"According to your study hours i.e {hours}, you may Fail\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A90J9JGO8bK-","executionInfo":{"status":"ok","timestamp":1755018819946,"user_tz":-330,"elapsed":2091,"user":{"displayName":"Tanish Khan","userId":"12647544731517487695"}},"outputId":"9b1c2321-ba54-4331-e0fa-1f898ea1357d"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the number of hours you studies:7\n","According to your study hours i.e 7.0, you may Pass\n"]}]}]}